{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01d2c398-3a41-4128-b9f5-a11e8f352095",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cecb0a9-ea49-415c-ba13-4c0fbd56ff58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-03 03:57:23.933730\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import igraph as ig\n",
    "import scanpy as sc\n",
    "import scanpy.external as sce\n",
    "import triku as tk\n",
    "\n",
    "#Plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#utils\n",
    "from datetime import datetime\n",
    "from scipy.sparse import csr_matrix, isspmatrix\n",
    "\n",
    "sc.settings.verbosity = 3\n",
    "sc.settings.set_figure_params(dpi=80)\n",
    "time_start = datetime.now()\n",
    "print(time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96cac09d-cdd8-462e-b1cc-df9981856cb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from src.configs import config\n",
    "from src.utils import utils as us\n",
    "from src.utils import visualise as vs\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "warnings.filterwarnings(\"once\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc97bb2-9cc5-4c68-a926-dc75dec4e50c",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be2bc2a7-4a8e-47fc-9f59-658f6a09d128",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24549, 15223)\n",
      "isspmatrix: True\n",
      "Loaded Filtered AnnData object: number of cells 24549\n",
      "Loaded Filtered AnnData object: number of genes 15223\n",
      "Available metadata for each cell:  Index(['timepoint', 'line', '10X_date', 'clusters', 'tSNE_1', 'tSNE_2',\n",
      "       'cluster', 'timepoint_mapped', 'batch', 'dataset', 'isHuman', 'isESC',\n",
      "       'n_genes_by_counts', 'total_counts', 'total_counts_mito',\n",
      "       'pct_counts_mito', 'total_counts_ribo', 'pct_counts_ribo',\n",
      "       'QC_doublets', 'n_genes', 'n_counts'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "adata = sc.read(config.PATHS.LOGS/'QC.h5ad')\n",
    "us.log(adata.shape)\n",
    "us.log('isspmatrix: {}'.format(isspmatrix(adata.X)))\n",
    "\n",
    "\n",
    "us.log('Loaded Filtered AnnData object: number of cells {}'.format(\n",
    "    adata.n_obs))\n",
    "us.log('Loaded Filtered AnnData object: number of genes {}'.format(\n",
    "    adata.n_vars) )\n",
    "us.log('Available metadata for each cell:  {}'.format(adata.obs.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21687ccb-9068-4ee1-94a6-ed3fb3bd2a7d",
   "metadata": {},
   "source": [
    "# Normalize and Log Transform data: Scanpy Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a66e4aa-5426-4817-a51a-3a4c49aadd6b",
   "metadata": {},
   "source": [
    "Basic Scanpy CPM Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ded6aedb-cee2-4a07-82f6-101d5f9d93ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing counts per cell The following highly-expressed genes are not considered during normalization factor computation:\n",
      "['ID3', 'BCYRN1', 'TMSB10', 'SST', 'AFP', 'ACTB', 'TMSB4X', 'TIMP1', 'IGF2', 'MDK', 'FTH1', 'MALAT1', 'GAL', 'APOA1', 'TAC3', 'DLK1', 'CRABP1', 'APOE', 'FTL', 'MGP', 'LUM', '7SK.2']\n",
      "    finished (0:00:00)\n"
     ]
    }
   ],
   "source": [
    "adata.layers['counts'] = adata.X.copy()\n",
    "sc.pp.normalize_total(adata, target_sum=1e6, exclude_highly_expressed=True)\n",
    "sc.pp.log1p(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c73df4-95b5-4ada-a80e-3afe856e4a9b",
   "metadata": {},
   "source": [
    "Store normalized counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "107ac557-2f7f-4307-afb7-881fe0839d8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adata.layers['lognormcounts'] = adata.X.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3956bf-529f-4841-8c72-3306367693e3",
   "metadata": {},
   "source": [
    "\n",
    "Alternative workflow: normalization by Scran\n",
    "References: Scran Paper | Scran R Vignette | Theis Scran Tutorial in scanpy |\n",
    "\n",
    "Normalizing cell-specific biases\n",
    "\n",
    "Cell-specific biases are normalized using the computeSumFactors() method, which implements the deconvolution strategy for scaling normalization (A. T. Lun, Bach, and Marioni 2016). This computes size factors that are used to scale the counts in each cell. The assumption is that most genes are not differentially expressed (DE) between cells , such that any differences in expression across the majority of genes represents some technical bias that should be removed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397a8b76-8b36-48db-bb84-eb7239b5206f",
   "metadata": {},
   "source": [
    "# Feature selection: Triku\n",
    "Sources: Triku Paper | Docs |\n",
    "\n",
    "The premise of triku is that, for genes with similar expression levels, the expression pattern can be categorized in three states:\n",
    "\n",
    "    i: the gene is expressed throughout the cells with similar expression levels (a): NO useful information about specific cell types associated to that gene\n",
    "    ii: the expression of the gene can be localized in a subset of cells, which can in turn be:\n",
    "        Transcriptomically different cells (b1) (i.e. cells that are not neighbours in the dimensionally reduced map)\n",
    "        Transcriptomically similar cells (b2) (neighbours): the gene is more probably biologically relevant for that population\n",
    "\n",
    "Triku aims to select genes of case (b2) while avoiding the selection of genes of case (a) and (b1).\n",
    "\n",
    "It does so by looking at the expression in the nearest neighbours\n",
    "PROs of this method:\n",
    "\n",
    "    selects more biologically relevant genes\n",
    "    avoids selection of mitocondrial and ribosomal genes\n",
    "    tends to select a lower number of HVGs aiding downstream computations\n",
    "\n",
    "The Algorithm\n",
    "\n",
    "    Create a neighbour graph by selecting the k cells with the most similar transcriptome to each cell in the dataset kNN:\n",
    "    For each gene:\n",
    "        Obtain the distribution of the the kNN counts summing the counts of each cell and its neighbors for each cell with positive expression in the dataset.\n",
    "        Simulate a null distribution, as above but considering k random cells instead of kNN ones.\n",
    "        Compare the kNN distribution with its corresponding null distribution Ã¬\n",
    "        Compute the Wasserstein distance between both distributions\n",
    "    Normalize Wasserstein distances\n",
    "    Select the features with highest Wasserstein distance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedbf1d5-831f-4b60-86dc-fde28eb51272",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compute neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "212208e6-d9f8-4af6-b3dd-f476cbe22b9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing PCA\n",
      "    with n_comps=50\n",
      "    finished (0:00:39)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vess/Distr/conda/envs/HT/lib/python3.9/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/vess/Distr/conda/envs/HT/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/vess/Distr/conda/envs/HT/lib/python3.9/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/vess/Distr/conda/envs/HT/lib/python3.9/site-packages/numba/np/ufunc/parallel.py:371: NumbaWarning: The TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\n",
      "  warnings.warn(problem)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:47)\n"
     ]
    }
   ],
   "source": [
    "sc.pp.pca(adata, use_highly_variable=False)\n",
    "# specify in case you want to try different HVG selection methods \n",
    "sc.pp.neighbors(\n",
    "    adata, metric='cosine', n_neighbors=int(0.5 * len(adata) ** 0.5)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613651d5-35a6-4894-bc09-3740965d8b01",
   "metadata": {},
   "source": [
    "## Identify HVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acbdfabd-63d1-4d79-b980-a08affc7abd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{170921: ['409b2']\n",
      "Categories (5, object): ['409b2', 'h9', 'joc', 'sandraA', 'sc102a1'], 171122: ['409b2', 'sandraA']\n",
      "Categories (5, object): ['409b2', 'h9', 'joc', 'sandraA', 'sc102a1'], 171212: ['409b2', 'sandraA']\n",
      "Categories (5, object): ['409b2', 'h9', 'joc', 'sandraA', 'sc102a1'], 180221: ['409b2', 'sandraA']\n",
      "Categories (5, object): ['409b2', 'h9', 'joc', 'sandraA', 'sc102a1'], 180321: ['409b2', 'sandraA']\n",
      "Categories (5, object): ['409b2', 'h9', 'joc', 'sandraA', 'sc102a1'], 180410: ['409b2', 'h9', 'sc102a1']\n",
      "Categories (5, object): ['409b2', 'h9', 'joc', 'sandraA', 'sc102a1'], 190327: ['sandraA']\n",
      "Categories (5, object): ['409b2', 'h9', 'joc', 'sandraA', 'sc102a1'], 190507: ['sandraA']\n",
      "Categories (5, object): ['409b2', 'h9', 'joc', 'sandraA', 'sc102a1'], 200818: ['sc102a1', 'h9', 'joc']\n",
      "Categories (5, object): ['409b2', 'h9', 'joc', 'sandraA', 'sc102a1'], 200908: ['joc']\n",
      "Categories (5, object): ['409b2', 'h9', 'joc', 'sandraA', 'sc102a1'], 200920: ['joc', 'h9', 'sc102a1']\n",
      "Categories (5, object): ['409b2', 'h9', 'joc', 'sandraA', 'sc102a1']}\n"
     ]
    }
   ],
   "source": [
    "if config.PROTO.SUBSET.BATCH_KEY is not None:\n",
    "    groups = adata.obs.groupby(config.PROTO.SUBSET.BATCH_KEY).groups\n",
    "    print({ \n",
    "        k: adata.obs.loc[idxs].line.unique() \n",
    "        for k, idxs in groups.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63fb9de7-45da-44fb-87df-d07e9c25db6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Higly Variable Genes 5000\n",
      "Index(['PGAM4', 'TDGF1', 'RP11-466P24.7', 'C9orf135', 'SMPDL3B', 'LINC00678',\n",
      "       'RP4-792G4.2', 'ZSCAN10', 'RP11-1144P22.1', 'CLDN7', 'NANOG', 'BGN',\n",
      "       'SCGB3A2', 'FOXH1', 'GPR160', 'RP11-277L2.5', 'CDH1', 'POU5F1', 'PRODH',\n",
      "       'UTF1'],\n",
      "      dtype='object', name='Unnamed: 0')\n"
     ]
    }
   ],
   "source": [
    "if config.PROTO.SUBSET.HVG_ALGOS == 'triku':\n",
    "    tk.tl.triku(\n",
    "        adata, use_raw=False,\n",
    "        n_features=config.PROTO.SUBSET.NB_HIGHLY_VARIABLE)\n",
    "    us.log(\n",
    "        'Number of Higly Variable Genes',\n",
    "        len(adata.var_names[adata.var['highly_variable'] == True]))\n",
    "\n",
    "    Top20Triku = adata.var.sort_values(\n",
    "        by=['triku_distance'], ascending=False).head(20).index\n",
    "    print(Top20Triku)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5cc2d2c-52db-4a5e-979e-34d217a5143d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config.PROTO.SUBSET.HVG_ALGOS == 'hvgsc':\n",
    "    adata.obs[config.PROTO.SUBSET.BATCH_KEY] = adata.obs[\n",
    "        config.PROTO.SUBSET.BATCH_KEY].astype(str)\n",
    "    sc.pp.highly_variable_genes(\n",
    "        adata, n_top_genes=config.PROTO.SUBSET.NB_HIGHLY_VARIABLE,\n",
    "        batch_key=config.PROTO.SUBSET.BATCH_KEY,\n",
    "    )\n",
    "    sc.pl.highly_variable_genes(adata)\n",
    "\n",
    "    us.log(\n",
    "        'Number of Higly Variable Genes', \n",
    "        len(adata.var_names[adata.var['highly_variable'] == True]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67428d80-9355-4625-a2ec-10c0bb7a1d81",
   "metadata": {},
   "source": [
    "Batch effect could influence HVG selection.\n",
    "\n",
    "You can consider to correct (e.g. with Harmony) the neighbors used to compute the HVGs. For this dataset we did not notice a big difference between the two procedures.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dd758e-00a9-4f5a-816e-fa9afd1a5b22",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4e7557d-02ed-46a2-b03e-3c20e00c728c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:05:02.183112\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del adata.uns['triku_params']\n",
    "except: pass\n",
    "\n",
    "adata.write(config.PATHS.LOGS/'Norm.h5ad')\n",
    "us.log(datetime.now() - time_start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
